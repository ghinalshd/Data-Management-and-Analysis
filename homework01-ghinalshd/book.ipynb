{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Necessary Information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Book #1: Crime and Punishment (1866) by Fyodor Dostoevsky**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- URL: https://www.gutenberg.org/cache/epub/2554/pg2554-images.html\n",
    "- License: Public Domain\n",
    "- Encoding: UTF-8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Book #2: The Great Gatsby (1925) by F. Scott Fitzgerald**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- URL: https://www.gutenberg.org/cache/epub/64317/pg64317-images.html\n",
    "- License: Public Domain\n",
    "- Encoding: UTF-8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Questions To Answer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- Who was the most frequently mentioned character in The Great Gatsby?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- How many chapters is there in Crime and Punishment?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- What are the top 20 most frequently mentioned words in both books?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import string\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for the books\n",
    "book1_path = os.path.join('data', 'crimeandpunishment.txt')\n",
    "book2_path = os.path.join('data', 'thegreatgatsby.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read the books\n",
    "with open(book1_path, 'r', encoding='utf-8') as file1:\n",
    "    book1_text = file1.read()\n",
    "\n",
    "with open(book2_path, 'r', encoding='utf-8') as file2:\n",
    "    book2_text = file2.read()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the first question, I will begin with preprocessing the text by removing any punctuation, converting to lowercase and splitting into words for easy and accurate implementation/analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    return words\n",
    "gatsby_words = preprocess_text(book1_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will define a list of character names to count mentions. The list of characters have been taken from the following website: https://www.sparknotes.com/lit/gatsby/characters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_names = [\"gatsby\", \"daisy\", \"tom\", \"nick\", \"myrtle\", \"jordan\", \"george\", \"meyer\", \"owl\", \"klipspringer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'tom': 81, 'owl': 60, 'nick': 4})\n"
     ]
    }
   ],
   "source": [
    "# Count the mentions of each character in the text.\n",
    "def character_frequency(words, character_names):\n",
    "    character_counts = Counter()\n",
    "    \n",
    "    for word in words:\n",
    "        for character in character_names:\n",
    "            if character in word:\n",
    "                character_counts[character] += 1\n",
    "    \n",
    "    return character_counts\n",
    "\n",
    "gatsby_character_counts = character_frequency(gatsby_words, character_names)\n",
    "print(gatsby_character_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Owl: 60 mentions\n",
      "Tom: 81 mentions\n",
      "Nick: 4 mentions\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store character mentions\n",
    "character_mentions = dict(gatsby_character_counts)\n",
    "for character, count in character_mentions.items():\n",
    "    print(f\"{character.capitalize()}: {count} mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_character, frequency = gatsby_character_counts.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequently mentioned character in 'The Great Gatsby' is Tom with 81 mentions.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The most frequently mentioned character in 'The Great Gatsby' is {most_frequent_character.capitalize()} with {frequency} mentions.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the second question, I am going to define a pattern that indicates the parts and chapters of the book. In the code below, I used the 're' (regular expressions) module to help match and extract the necessary information since the book displays the chapter and part numbers in a specific pattern: \"PART X\" or \"CHAPTER Y\" in which X and Y are greek numerical letters, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chapters(book_text):\n",
    "    # Use regular expressions to find chapter headings with the pattern \"CHAPTER X\".\n",
    "    chapter_pattern = r'CHAPTER [IVXLCDM]+'\n",
    "    part_pattern = r'PART [IVXLCDM]+'\n",
    "    chapter_headings = re.findall(chapter_pattern, book_text)\n",
    "    part_headings = re.findall(part_pattern, book_text)\n",
    "    \n",
    "    # Count the total number of chapters.\n",
    "    total_chapters = len(chapter_headings)\n",
    "    total_parts = len(part_headings)\n",
    "    \n",
    "    # Print the chapter headings and parts as well as their total counts\n",
    "    for part in part_headings:\n",
    "        print(part)\n",
    "    \n",
    "    print(f\"\\nTotal Number of Parts: {total_parts}\")   \n",
    "    \n",
    "    print(\"\\n-----------------------------------------------------------\\n\")\n",
    "    \n",
    "    for chapter in chapter_headings:\n",
    "        print(chapter)\n",
    " \n",
    "    print(f\"\\nTotal Number of Chapters: {total_chapters}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents for Crime and Punishment\n",
      "\n",
      "PART I\n",
      "PART II\n",
      "PART III\n",
      "PART IV\n",
      "PART V\n",
      "PART VI\n",
      "\n",
      "Total Number of Parts: 6\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "CHAPTER I\n",
      "CHAPTER II\n",
      "CHAPTER III\n",
      "CHAPTER IV\n",
      "CHAPTER V\n",
      "CHAPTER VI\n",
      "CHAPTER VII\n",
      "CHAPTER I\n",
      "CHAPTER II\n",
      "CHAPTER III\n",
      "CHAPTER IV\n",
      "CHAPTER V\n",
      "CHAPTER VI\n",
      "CHAPTER VII\n",
      "CHAPTER I\n",
      "CHAPTER II\n",
      "CHAPTER III\n",
      "CHAPTER IV\n",
      "CHAPTER V\n",
      "CHAPTER VI\n",
      "CHAPTER I\n",
      "CHAPTER II\n",
      "CHAPTER III\n",
      "CHAPTER IV\n",
      "CHAPTER V\n",
      "CHAPTER VI\n",
      "CHAPTER I\n",
      "CHAPTER II\n",
      "CHAPTER III\n",
      "CHAPTER IV\n",
      "CHAPTER V\n",
      "CHAPTER I\n",
      "CHAPTER II\n",
      "CHAPTER III\n",
      "CHAPTER IV\n",
      "CHAPTER V\n",
      "CHAPTER VI\n",
      "CHAPTER VII\n",
      "CHAPTER VIII\n",
      "\n",
      "Total Number of Chapters: 39\n"
     ]
    }
   ],
   "source": [
    "print('Table of Contents for Crime and Punishment\\n')\n",
    "extract_chapters(book1_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the third question, I am going to define a function to find the most frequent words in a text. However, I will firstly begin by identifying common stop words like \"a\" and \"of\" to make my analysis more accurate. By doing so, I can get more understanding on the actual diction of the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of common stop words\n",
    "stop_words = [\"a\", \"an\", \"the\", \"and\", \"of\", \"she\", \"he\", \"it\", \"in\", \"to\",\n",
    "              \"in\", \"was\", \"had\", \"that\", \"with\", \"her\", \"him\", \"his\", \n",
    "             \"i\", \"a\", \"s\", \"at\", \"but\", \"you\", \"me\", \"as\", \"they\", \"them\", \n",
    "             \"my\", \"from\", \"this\", \"that\", \"is\", \"not\", \"there\", \"t\", \n",
    "             \"be\", \"so\", \"has\", \"have\", \"we\", \"on\", \"for\", \"like\", \n",
    "             \"by\", \"one\", \"or\", \"were\", \"your\",\"will\", \"if\", \"do\", \"been\", \n",
    "             \"am\", \"as\", \"said\"]\n",
    "\n",
    "def tokenize_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize by splitting on spaces and removing punctuation\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    # Filter out stop words\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the most frequent words in text\n",
    "def find_most_frequent_words(text, top_n=20):\n",
    "    # Tokenize the text\n",
    "    words = tokenize_text(text)\n",
    "    \n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Get the top N most frequent words\n",
    "    top_words = word_counts.most_common(top_n)\n",
    "    \n",
    "    return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Frequent Words in The Great Gatsby:\n",
      "\n",
      "gatsby: 268\n",
      "all: 239\n",
      "out: 214\n",
      "up: 194\n",
      "tom: 191\n",
      "daisy: 186\n",
      "into: 168\n",
      "about: 159\n",
      "when: 147\n",
      "what: 147\n",
      "then: 144\n",
      "over: 143\n",
      "down: 118\n",
      "who: 117\n",
      "man: 114\n",
      "no: 113\n",
      "back: 109\n",
      "came: 108\n",
      "any: 105\n",
      "some: 104\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Top 20 Most Frequent Words in Crime and Punishment:\n",
      "\n",
      "all: 1318\n",
      "what: 1231\n",
      "are: 870\n",
      "raskolnikov: 785\n",
      "no: 703\n",
      "out: 685\n",
      "up: 658\n",
      "would: 573\n",
      "now: 564\n",
      "about: 538\n",
      "how: 536\n",
      "know: 530\n",
      "too: 503\n",
      "did: 497\n",
      "could: 496\n",
      "come: 480\n",
      "man: 479\n",
      "then: 471\n",
      "very: 466\n",
      "don: 464\n"
     ]
    }
   ],
   "source": [
    "gatsby_top_words = find_most_frequent_words(book2_text)\n",
    "crime_top_words = find_most_frequent_words(book1_text)\n",
    "\n",
    "print(\"Top 20 Most Frequent Words in The Great Gatsby:\\n\")\n",
    "for word, count in gatsby_top_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "print(\"\\n-----------------------------------------------------------\")\n",
    "print(\"\\nTop 20 Most Frequent Words in Crime and Punishment:\\n\")\n",
    "for word, count in crime_top_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
